{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование работы компании Procrastinate Pro+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Описание проекта.\n",
    "Последние несколько месяцев компания терпит убытки, несмотря на вложения в рекламу. \n",
    "\n",
    "Основная цель разобраться в причинах и помочь компании выйти в плюс.\n",
    "\n",
    "Есть данные о привлеченных пользователях с 01.05.2019 по 27.10.2019:  \n",
    "- логи серверов с данными об их посещениях, \n",
    "- выгрузка их покупок за этот период, \n",
    "- рекламные расходы.\n",
    "\n",
    "##### Цель проекта изучить:\n",
    "-  откуда приходят пользователи и какими устройствами они пользуются\n",
    "-  сколько стоит привлечение пользователей из различных рекламных каналов\n",
    "-  сколько денег приносит каждый клиент\n",
    "-  когда расходы на привлечение клиента окупаются\n",
    "-  какие факторы мешают привлечению клиентов\n",
    "\n",
    "##### План работы:\n",
    "- Загрузить данные\n",
    "- Произвести предобработку данных. Проверить на пропуски значений, дубликаты, ошибки типов данных.\n",
    "- Визуализировать и изучить обрботанные данные, выполнить первоначальные наблюдения.\n",
    "- Произвести расчеты на основе полученных данных, выявить закономерности. \n",
    "- Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    visits = pd.read_csv('C:\\\\Users\\\\tema-\\\\Downloads\\\\Jupyter\\\\Doc_csv\\\\visits_info_short.csv')\n",
    "    orders = pd.read_csv('C:\\\\Users\\\\tema-\\\\Downloads\\\\Jupyter\\\\Doc_csv\\\\orders_info_short.csv')\n",
    "    costs = pd.read_csv('C:\\\\Users\\\\tema-\\\\Downloads\\\\Jupyter\\\\Doc_csv\\\\costs_info_short.csv')\n",
    "except:\n",
    "    visits = pd.read_csv('/datasets/visits_info_short.csv')\n",
    "    orders = pd.read_csv('/datasets/orders_info_short.csv')\n",
    "    costs = pd.read_csv('/datasets/costs_info_short.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные о посещениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Данные о показах'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Id</th>\n",
       "      <th>Region</th>\n",
       "      <th>Device</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Session Start</th>\n",
       "      <th>Session End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>981449118918</td>\n",
       "      <td>United States</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>organic</td>\n",
       "      <td>2019-05-01 02:36:01</td>\n",
       "      <td>2019-05-01 02:45:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278965908054</td>\n",
       "      <td>United States</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>organic</td>\n",
       "      <td>2019-05-01 04:46:31</td>\n",
       "      <td>2019-05-01 04:47:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>590706206550</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mac</td>\n",
       "      <td>organic</td>\n",
       "      <td>2019-05-01 14:09:25</td>\n",
       "      <td>2019-05-01 15:32:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326433527971</td>\n",
       "      <td>United States</td>\n",
       "      <td>Android</td>\n",
       "      <td>TipTop</td>\n",
       "      <td>2019-05-01 00:29:59</td>\n",
       "      <td>2019-05-01 00:54:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349773784594</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mac</td>\n",
       "      <td>organic</td>\n",
       "      <td>2019-05-01 03:33:35</td>\n",
       "      <td>2019-05-01 03:57:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309896</th>\n",
       "      <td>329994900775</td>\n",
       "      <td>UK</td>\n",
       "      <td>PC</td>\n",
       "      <td>LeapBob</td>\n",
       "      <td>2019-10-31 13:28:12</td>\n",
       "      <td>2019-10-31 14:39:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309897</th>\n",
       "      <td>334903592310</td>\n",
       "      <td>France</td>\n",
       "      <td>PC</td>\n",
       "      <td>lambdaMediaAds</td>\n",
       "      <td>2019-10-31 22:14:52</td>\n",
       "      <td>2019-10-31 22:39:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309898</th>\n",
       "      <td>540102010126</td>\n",
       "      <td>Germany</td>\n",
       "      <td>PC</td>\n",
       "      <td>organic</td>\n",
       "      <td>2019-10-31 01:40:48</td>\n",
       "      <td>2019-10-31 01:41:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309899</th>\n",
       "      <td>308736936846</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Mac</td>\n",
       "      <td>organic</td>\n",
       "      <td>2019-10-31 07:37:34</td>\n",
       "      <td>2019-10-31 07:37:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309900</th>\n",
       "      <td>109329042535</td>\n",
       "      <td>Germany</td>\n",
       "      <td>PC</td>\n",
       "      <td>lambdaMediaAds</td>\n",
       "      <td>2019-10-31 14:17:43</td>\n",
       "      <td>2019-10-31 15:17:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309901 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             User Id         Region   Device         Channel  \\\n",
       "0       981449118918  United States   iPhone         organic   \n",
       "1       278965908054  United States   iPhone         organic   \n",
       "2       590706206550  United States      Mac         organic   \n",
       "3       326433527971  United States  Android          TipTop   \n",
       "4       349773784594  United States      Mac         organic   \n",
       "...              ...            ...      ...             ...   \n",
       "309896  329994900775             UK       PC         LeapBob   \n",
       "309897  334903592310         France       PC  lambdaMediaAds   \n",
       "309898  540102010126        Germany       PC         organic   \n",
       "309899  308736936846        Germany      Mac         organic   \n",
       "309900  109329042535        Germany       PC  lambdaMediaAds   \n",
       "\n",
       "              Session Start          Session End  \n",
       "0       2019-05-01 02:36:01  2019-05-01 02:45:01  \n",
       "1       2019-05-01 04:46:31  2019-05-01 04:47:35  \n",
       "2       2019-05-01 14:09:25  2019-05-01 15:32:08  \n",
       "3       2019-05-01 00:29:59  2019-05-01 00:54:25  \n",
       "4       2019-05-01 03:33:35  2019-05-01 03:57:40  \n",
       "...                     ...                  ...  \n",
       "309896  2019-10-31 13:28:12  2019-10-31 14:39:29  \n",
       "309897  2019-10-31 22:14:52  2019-10-31 22:39:36  \n",
       "309898  2019-10-31 01:40:48  2019-10-31 01:41:31  \n",
       "309899  2019-10-31 07:37:34  2019-10-31 07:37:55  \n",
       "309900  2019-10-31 14:17:43  2019-10-31 15:17:04  \n",
       "\n",
       "[309901 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Данные о заказах'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Id</th>\n",
       "      <th>Event Dt</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188246423999</td>\n",
       "      <td>2019-05-01 23:09:52</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174361394180</td>\n",
       "      <td>2019-05-01 12:24:04</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529610067795</td>\n",
       "      <td>2019-05-01 11:34:04</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319939546352</td>\n",
       "      <td>2019-05-01 15:34:40</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366000285810</td>\n",
       "      <td>2019-05-01 13:59:51</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40207</th>\n",
       "      <td>651604369137</td>\n",
       "      <td>2019-10-31 16:19:07</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40208</th>\n",
       "      <td>275341387049</td>\n",
       "      <td>2019-10-31 01:17:17</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40209</th>\n",
       "      <td>374656616484</td>\n",
       "      <td>2019-10-31 06:17:29</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40210</th>\n",
       "      <td>168548862926</td>\n",
       "      <td>2019-10-31 22:46:19</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40211</th>\n",
       "      <td>329994900775</td>\n",
       "      <td>2019-10-31 13:29:06</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40212 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            User Id             Event Dt  Revenue\n",
       "0      188246423999  2019-05-01 23:09:52     4.99\n",
       "1      174361394180  2019-05-01 12:24:04     4.99\n",
       "2      529610067795  2019-05-01 11:34:04     4.99\n",
       "3      319939546352  2019-05-01 15:34:40     4.99\n",
       "4      366000285810  2019-05-01 13:59:51     4.99\n",
       "...             ...                  ...      ...\n",
       "40207  651604369137  2019-10-31 16:19:07     4.99\n",
       "40208  275341387049  2019-10-31 01:17:17     4.99\n",
       "40209  374656616484  2019-10-31 06:17:29     4.99\n",
       "40210  168548862926  2019-10-31 22:46:19     4.99\n",
       "40211  329994900775  2019-10-31 13:29:06     4.99\n",
       "\n",
       "[40212 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Данные о расходах'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>Channel</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>78.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>136.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>122.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>lambdaMediaAds</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>lambdaMediaAds</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>lambdaMediaAds</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>lambdaMediaAds</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>lambdaMediaAds</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt         Channel  costs\n",
       "0     2019-05-01        FaceBoom  113.3\n",
       "1     2019-05-02        FaceBoom   78.1\n",
       "2     2019-05-03        FaceBoom   85.8\n",
       "3     2019-05-04        FaceBoom  136.4\n",
       "4     2019-05-05        FaceBoom  122.1\n",
       "...          ...             ...    ...\n",
       "1795  2019-10-23  lambdaMediaAds    4.0\n",
       "1796  2019-10-24  lambdaMediaAds    6.4\n",
       "1797  2019-10-25  lambdaMediaAds    8.8\n",
       "1798  2019-10-26  lambdaMediaAds    8.8\n",
       "1799  2019-10-27  lambdaMediaAds   12.0\n",
       "\n",
       "[1800 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Данные о показах', visits)\n",
    "display('Данные о заказах', orders)\n",
    "display('Данные о расходах', costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 309901 entries, 0 to 309900\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   User Id        309901 non-null  int64 \n",
      " 1   Region         309901 non-null  object\n",
      " 2   Device         309901 non-null  object\n",
      " 3   Channel        309901 non-null  object\n",
      " 4   Session Start  309901 non-null  object\n",
      " 5   Session End    309901 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 14.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Данные о показах'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40212 entries, 0 to 40211\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   User Id   40212 non-null  int64  \n",
      " 1   Event Dt  40212 non-null  object \n",
      " 2   Revenue   40212 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 942.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Данные о заказах'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800 entries, 0 to 1799\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   dt       1800 non-null   object \n",
      " 1   Channel  1800 non-null   object \n",
      " 2   costs    1800 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 42.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Данные о расходах'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Данные о показах', visits.info())\n",
    "display('Данные о заказах', orders.info())\n",
    "display('Данные о расходах', costs.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоги обзора :\n",
    "- типы данных с датой не приведены к нужному формату\n",
    "- наименования стобцов в разном регистре, с пробелами\n",
    "- пропусков данных не обнаружено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура visits:\n",
    "- User Id — уникальный идентификатор пользователя,\n",
    "- Region — страна пользователя,\n",
    "- Device — тип устройства пользователя,\n",
    "- Channel — идентификатор источника перехода,\n",
    "- Session Start — дата и время начала сессии,\n",
    "- Session End — дата и время окончания сессии.\n",
    "\n",
    "Структура orders:\n",
    "- User Id — уникальный идентификатор пользователя,\n",
    "- Event Dt — дата и время покупки,\n",
    "- Revenue — сумма заказа.\n",
    "\n",
    "Структура costs:\n",
    "- dt — дата проведения рекламной кампании,\n",
    "- Channel — идентификатор рекламного источника,\n",
    "- costs — расходы на эту кампанию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1.1 Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наименования столбцов приведем к нужному регистру и пробелы заменим нижним подчеркиванием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'region', 'device', 'channel', 'session_start',\n",
       "       'session_end'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'event_dt', 'revenue'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['dt', 'channel', 'costs'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visits.columns = [name.lower().replace(' ', '_') for name in visits.columns]\n",
    "orders.columns = [name.lower().replace(' ', '_') for name in orders.columns]\n",
    "costs.columns = costs.columns.str.lower()\n",
    "\n",
    "display(visits.columns)\n",
    "display(orders.columns)\n",
    "display(costs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типы с датой приведем к нужному формату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 309901 entries, 0 to 309900\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   user_id        309901 non-null  int64         \n",
      " 1   region         309901 non-null  object        \n",
      " 2   device         309901 non-null  object        \n",
      " 3   channel        309901 non-null  object        \n",
      " 4   session_start  309901 non-null  datetime64[ns]\n",
      " 5   session_end    309901 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(3)\n",
      "memory usage: 14.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40212 entries, 0 to 40211\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   user_id   40212 non-null  int64         \n",
      " 1   event_dt  40212 non-null  datetime64[ns]\n",
      " 2   revenue   40212 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 942.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800 entries, 0 to 1799\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   dt       1800 non-null   object \n",
      " 1   channel  1800 non-null   object \n",
      " 2   costs    1800 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 42.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visits['session_start'] = pd.to_datetime(visits['session_start'])\n",
    "visits['session_end'] = pd.to_datetime(visits['session_end'])\n",
    "orders['event_dt'] = pd.to_datetime(orders['event_dt'])\n",
    "costs['dt'] = pd.to_datetime(costs['dt']).dt.date\n",
    "display(visits.info())\n",
    "display(orders.info())\n",
    "display(costs.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем наличие дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Посещения'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Заказы'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Расходы'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Посещения' ,visits.duplicated().sum())\n",
    "display('Заказы', orders.duplicated().sum())\n",
    "display('Расходы' ,costs.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vsKinGUWVwk"
   },
   "source": [
    "### Шаг 2.  Зададим функции для вычислений Retention Rate, Conversion, LTV, ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для вычисления значений метрик:\n",
    "\n",
    "- `get_profiles()` — для создания профилей пользователей,\n",
    "- `get_retention()` — для подсчёта Retention Rate,\n",
    "- `get_conversion()` — для подсчёта конверсии,\n",
    "- `get_ltv()` — для подсчёта LTV.\n",
    "\n",
    "Функции для построения графиков:\n",
    "\n",
    "- `filter_data()` — для сглаживания данных,\n",
    "- `plot_retention()` — для построения графика Retention Rate,\n",
    "- `plot_conversion()` — для построения графика конверсии,\n",
    "- `plot_ltv_roi` — для визуализации LTV и ROI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания профиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profiles(sessions, orders, ad_costs):\n",
    "\n",
    "    # находим параметры первых посещений\n",
    "    profiles = (\n",
    "        sessions.sort_values(by=['user_id', 'session_start'])\n",
    "        .groupby('user_id')\n",
    "        .agg(\n",
    "            {\n",
    "                'session_start': 'first',\n",
    "                'channel': 'first',\n",
    "                'device': 'first',\n",
    "                'region': 'first',\n",
    "            }\n",
    "        )\n",
    "        .rename(columns={'session_start': 'first_ts'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # для когортного анализа определяем дату первого посещения\n",
    "    # и первый день месяца, в который это посещение произошло\n",
    "    profiles['dt'] = profiles['first_ts'].dt.date\n",
    "    profiles['month'] = profiles['first_ts'].astype('datetime64[M]')\n",
    "\n",
    "    # добавляем признак платящих пользователей\n",
    "    profiles['payer'] = profiles['user_id'].isin(orders['user_id'].unique())\n",
    "\n",
    "   \n",
    "    # считаем количество уникальных пользователей\n",
    "    # с одинаковыми источником и датой привлечения\n",
    "    new_users = (\n",
    "        profiles.groupby(['dt', 'channel'])\n",
    "        .agg({'user_id': 'nunique'})\n",
    "        .rename(columns={'user_id': 'unique_users'})\n",
    "        .reset_index()\n",
    "    )\n",
    "        \n",
    "    # объединяем траты на рекламу и число привлечённых пользователей\n",
    "    ad_costs['dt'] = ad_costs['dt'].dt.date\n",
    "    ad_costs = ad_costs.merge(new_users, on=['dt', 'channel'], how='left')\n",
    "\n",
    "    # делим рекламные расходы на число привлечённых пользователей\n",
    "    ad_costs['acquisition_cost'] = ad_costs['costs'] / ad_costs['unique_users']\n",
    "\n",
    "    # добавляем стоимость привлечения в профили\n",
    "    profiles = profiles.merge(\n",
    "        ad_costs[['dt', 'channel', 'acquisition_cost']],\n",
    "        on=['dt', 'channel'],\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "    # стоимость привлечения органических пользователей равна нулю\n",
    "    profiles['acquisition_cost'] = profiles['acquisition_cost'].fillna(0)\n",
    "\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для расчёта удержания(Retention Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для расчёта удержания\n",
    "\n",
    "def get_retention(\n",
    "    profiles,\n",
    "    sessions,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # добавляем столбец payer в передаваемый dimensions список\n",
    "    dimensions = ['payer'] + dimensions\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # собираем «сырые» данные для расчёта удержания\n",
    "    result_raw = result_raw.merge(\n",
    "        sessions[['user_id', 'session_start']], on='user_id', how='left'\n",
    "    )\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['session_start'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "\n",
    "    # функция для группировки таблицы по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='user_id', aggfunc='nunique'\n",
    "        )\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # получаем таблицу удержания\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # получаем таблицу динамики удержания\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    # возвращаем обе таблицы и сырые данные\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчёта конверсии Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversion(\n",
    "    profiles,\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # определяем дату и время первой покупки для каждого пользователя\n",
    "    first_purchases = (\n",
    "        purchases.sort_values(by=['user_id', 'event_dt'])\n",
    "        .groupby('user_id')\n",
    "        .agg({'event_dt': 'first'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # добавляем данные о покупках в профили\n",
    "    result_raw = result_raw.merge(\n",
    "        first_purchases[['user_id', 'event_dt']], on='user_id', how='left'\n",
    "    )\n",
    "\n",
    "    # рассчитываем лайфтайм для каждой покупки\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "\n",
    "    # группируем по cohort, если в dimensions ничего нет\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users' \n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # функция для группировки таблицы по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='user_id', aggfunc='nunique'\n",
    "        )\n",
    "        result = result.fillna(0).cumsum(axis = 1)\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        # делим каждую «ячейку» в строке на размер когорты\n",
    "        # и получаем conversion rate\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # получаем таблицу конверсии\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # для таблицы динамики конверсии убираем 'cohort' из dimensions\n",
    "    if 'cohort' in dimensions: \n",
    "        dimensions = []\n",
    "\n",
    "    # получаем таблицу динамики конверсии\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    # возвращаем обе таблицы и сырые данные\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подсчёта LTV и ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ltv(\n",
    "    profiles,\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "  \n",
    "    # добавляем данные о покупках в профили\n",
    "    result_raw = result_raw.merge(\n",
    "        purchases[['user_id', 'event_dt', 'revenue']], on='user_id', how='left'\n",
    "    )\n",
    "    \n",
    "    # рассчитываем лайфтайм пользователя для каждой покупки\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "    \n",
    "    # группируем по cohort, если в dimensions ничего нет\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users'\n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # функция группировки по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        # строим «треугольную» таблицу выручки\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='revenue', aggfunc='sum'\n",
    "        )\n",
    "        # находим сумму выручки с накоплением\n",
    "        result = result.fillna(0).cumsum(axis=1)\n",
    "        # вычисляем размеры когорт\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        # объединяем размеры когорт и таблицу выручки\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        # считаем LTV: делим каждую «ячейку» в строке на размер когорты\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        # исключаем все лайфтаймы, превышающие горизонт анализа\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        # восстанавливаем размеры когорт\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # собираем датафрейм с данными пользователей и значениями CAC, \n",
    "        # добавляя параметры из dimensions\n",
    "        cac = df[['user_id', 'acquisition_cost'] + dims].drop_duplicates()\n",
    "\n",
    "        # считаем средний CAC по параметрам из dimensions\n",
    "        cac = (\n",
    "            cac.groupby(dims)\n",
    "            .agg({'acquisition_cost': 'mean'})\n",
    "            .rename(columns={'acquisition_cost': 'cac'})\n",
    "        )\n",
    "\n",
    "        # считаем ROI: делим LTV на CAC\n",
    "        roi = result.div(cac['cac'], axis=0)\n",
    "\n",
    "        # удаляем строки с бесконечным ROI\n",
    "        roi = roi[~roi['cohort_size'].isin([np.inf])]\n",
    "\n",
    "        # восстанавливаем размеры когорт в таблице ROI\n",
    "        roi['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # добавляем CAC в таблицу ROI\n",
    "        roi['cac'] = cac['cac']\n",
    "\n",
    "        # в финальной таблице оставляем размеры когорт, CAC\n",
    "        # и ROI в лайфтаймы, не превышающие горизонт анализа\n",
    "        roi = roi[['cohort_size', 'cac'] + list(range(horizon_days))]\n",
    "\n",
    "        # возвращаем таблицы LTV и ROI\n",
    "        return result, roi\n",
    "\n",
    "    # получаем таблицы LTV и ROI\n",
    "    result_grouped, roi_grouped = group_by_dimensions(\n",
    "        result_raw, dimensions, horizon_days\n",
    "    )\n",
    "\n",
    "    # для таблиц динамики убираем 'cohort' из dimensions\n",
    "    if 'cohort' in dimensions:\n",
    "        dimensions = []\n",
    "\n",
    "    # получаем таблицы динамики LTV и ROI\n",
    "    result_in_time, roi_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        result_raw,  # сырые данные\n",
    "        result_grouped,  # таблица LTV\n",
    "        result_in_time,  # таблица динамики LTV\n",
    "        roi_grouped,  # таблица ROI\n",
    "        roi_in_time,  # таблица динамики ROI\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сглаживания данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для сглаживания фрейма\n",
    "\n",
    "def filter_data(df, window):\n",
    "    # для каждого столбца применяем скользящее среднее\n",
    "    for column in df.columns.values:\n",
    "        df[column] = df[column].rolling(window).mean() \n",
    "    return df\n",
    "\n",
    "# функция для визуализации LTV и ROI\n",
    "\n",
    "def plot_ltv_roi(ltv, ltv_history, roi, roi_history, horizon, window=7):\n",
    "\n",
    "    # задаём сетку отрисовки графиков\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # из таблицы ltv исключаем размеры когорт\n",
    "    ltv = ltv.drop(columns=['cohort_size'])\n",
    "    # в таблице динамики ltv оставляем только нужный лайфтайм\n",
    "    ltv_history = ltv_history.drop(columns=['cohort_size'])[[horizon - 1]]\n",
    "\n",
    "    # стоимость привлечения запишем в отдельный фрейм\n",
    "    cac_history = roi_history[['cac']]\n",
    "\n",
    "    # из таблицы roi исключаем размеры когорт и cac\n",
    "    roi = roi.drop(columns=['cohort_size', 'cac'])\n",
    "    # в таблице динамики roi оставляем только нужный лайфтайм\n",
    "    roi_history = roi_history.drop(columns=['cohort_size', 'cac'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # первый график — кривые ltv\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    ltv.T.plot(grid=True, ax=ax1)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('LTV')\n",
    "\n",
    "    # второй график — динамика ltv\n",
    "    ax2 = plt.subplot(3, 2, 2, sharey=ax1)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in ltv_history.index.names if name not in ['dt']]\n",
    "    filtered_data = ltv_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax2)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика LTV пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    # третий график — динамика cac\n",
    "    ax3 = plt.subplot(3, 2, 3, sharey=ax1)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in cac_history.index.names if name not in ['dt']]\n",
    "    filtered_data = cac_history.pivot_table(\n",
    "        index='dt', columns=columns, values='cac', aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax3)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика стоимости привлечения пользователей')\n",
    "\n",
    "    # четвёртый график — кривые roi\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    roi.T.plot(grid=True, ax=ax4)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Уровень окупаемости')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('ROI')\n",
    "\n",
    "    # пятый график — динамика roi\n",
    "    ax5 = plt.subplot(3, 2, 5, sharey=ax4)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in roi_history.index.names if name not in ['dt']]\n",
    "    filtered_data = roi_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax5)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Уровень окупаемости')\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика ROI пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для визуализации удержания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для визуализации удержания\n",
    "\n",
    "def plot_retention(retention, retention_history, horizon, window=7):\n",
    "\n",
    "    # задаём размер сетки для графиков\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # исключаем размеры когорт и удержание первого дня\n",
    "    retention = retention.drop(columns=['cohort_size', 0])\n",
    "    # в таблице динамики оставляем только нужный лайфтайм\n",
    "    retention_history = retention_history.drop(columns=['cohort_size'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # если в индексах таблицы удержания только payer,\n",
    "    # добавляем второй признак — cohort\n",
    "    if retention.index.nlevels == 1:\n",
    "        retention['cohort'] = 'All users'\n",
    "        retention = retention.reset_index().set_index(['cohort', 'payer'])\n",
    "\n",
    "    # в таблице графиков — два столбца и две строки, четыре ячейки\n",
    "    # в первой строим кривые удержания платящих пользователей\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    retention.query('payer == True').droplevel('payer').T.plot(\n",
    "        grid=True, ax=ax1\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Удержание платящих пользователей')\n",
    "\n",
    "    # во второй ячейке строим кривые удержания неплатящих\n",
    "    # вертикальная ось — от графика из первой ячейки\n",
    "    ax2 = plt.subplot(2, 2, 2, sharey=ax1)\n",
    "    retention.query('payer == False').droplevel('payer').T.plot(\n",
    "        grid=True, ax=ax2\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Удержание неплатящих пользователей')\n",
    "\n",
    "    # в третьей ячейке — динамика удержания платящих\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    # получаем названия столбцов для сводной таблицы\n",
    "    columns = [\n",
    "        name\n",
    "        for name in retention_history.index.names\n",
    "        if name not in ['dt', 'payer']\n",
    "    ]\n",
    "    # фильтруем данные и строим график\n",
    "    filtered_data = retention_history.query('payer == True').pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax3)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title(\n",
    "        'Динамика удержания платящих пользователей на {}-й день'.format(\n",
    "            horizon\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # в чётвертой ячейке — динамика удержания неплатящих\n",
    "    ax4 = plt.subplot(2, 2, 4, sharey=ax3)\n",
    "    # фильтруем данные и строим график\n",
    "    filtered_data = retention_history.query('payer == False').pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax4)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title(\n",
    "        'Динамика удержания неплатящих пользователей на {}-й день'.format(\n",
    "            horizon\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для визуализации конверсии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для визуализации конверси\n",
    "\n",
    "def plot_conversion(conversion, conversion_history, horizon, window=7):\n",
    "\n",
    "    # задаём размер сетки для графиков\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # исключаем размеры когорт\n",
    "    conversion = conversion.drop(columns=['cohort_size'])\n",
    "    # в таблице динамики оставляем только нужный лайфтайм\n",
    "    conversion_history = conversion_history.drop(columns=['cohort_size'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # первый график — кривые конверсии\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    conversion.T.plot(grid=True, ax=ax1)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Конверсия пользователей')\n",
    "\n",
    "    # второй график — динамика конверсии\n",
    "    ax2 = plt.subplot(1, 2, 2, sharey=ax1)\n",
    "    columns = [\t\t\n",
    "        # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "        name for name in conversion_history.index.names if name not in ['dt']\n",
    "    ]\n",
    "    filtered_data = conversion_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax2)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика конверсии пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " для визуализации LTV и ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "igOfMgBpWVwl"
   },
   "outputs": [],
   "source": [
    "# функция для визуализации LTV и ROI\n",
    "\n",
    "def plot_ltv_roi(ltv, ltv_history, roi, roi_history, horizon, window=7):\n",
    "\n",
    "    # задаём сетку отрисовки графиков\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # из таблицы ltv исключаем размеры когорт\n",
    "    ltv = ltv.drop(columns=['cohort_size'])\n",
    "    # в таблице динамики ltv оставляем только нужный лайфтайм\n",
    "    ltv_history = ltv_history.drop(columns=['cohort_size'])[[horizon - 1]]\n",
    "\n",
    "    # стоимость привлечения запишем в отдельный фрейм\n",
    "    cac_history = roi_history[['cac']]\n",
    "\n",
    "    # из таблицы roi исключаем размеры когорт и cac\n",
    "    roi = roi.drop(columns=['cohort_size', 'cac'])\n",
    "    # в таблице динамики roi оставляем только нужный лайфтайм\n",
    "    roi_history = roi_history.drop(columns=['cohort_size', 'cac'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # первый график — кривые ltv\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    ltv.T.plot(grid=True, ax=ax1)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('LTV')\n",
    "\n",
    "    # второй график — динамика ltv\n",
    "    ax2 = plt.subplot(3, 2, 2, sharey=ax1)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in ltv_history.index.names if name not in ['dt']]\n",
    "    filtered_data = ltv_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax2)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика LTV пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    # третий график — динамика cac\n",
    "    ax3 = plt.subplot(3, 2, 3, sharey=ax1)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in cac_history.index.names if name not in ['dt']]\n",
    "    filtered_data = cac_history.pivot_table(\n",
    "        index='dt', columns=columns, values='cac', aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax3)\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика стоимости привлечения пользователей')\n",
    "\n",
    "    # четвёртый график — кривые roi\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    roi.T.plot(grid=True, ax=ax4)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Уровень окупаемости')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('ROI')\n",
    "\n",
    "    # пятый график — динамика roi\n",
    "    ax5 = plt.subplot(3, 2, 5, sharey=ax4)\n",
    "    # столбцами сводной таблицы станут все столбцы индекса, кроме даты\n",
    "    columns = [name for name in roi_history.index.names if name not in ['dt']]\n",
    "    filtered_data = roi_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax5)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Уровень окупаемости')\n",
    "    plt.xlabel('Дата привлечения')\n",
    "    plt.title('Динамика ROI пользователей на {}-й день'.format(horizon))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-KBT-KMWVwl"
   },
   "source": [
    "### ШАГ 3. Исследовательский анализ данных\n",
    "\n",
    "Составим таблицу профиля для пользователей.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast DatetimeArray to dtype datetime64[M]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m profiles \u001b[38;5;241m=\u001b[39m get_profiles(visits, orders, costs)\n\u001b[0;32m      2\u001b[0m profiles\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[92], line 22\u001b[0m, in \u001b[0;36mget_profiles\u001b[1;34m(sessions, orders, ad_costs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# для когортного анализа определяем дату первого посещения\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# и первый день месяца, в который это посещение произошло\u001b[39;00m\n\u001b[0;32m     21\u001b[0m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_ts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[1;32m---> 22\u001b[0m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_ts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[M]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# добавляем признак платящих пользователей\u001b[39;00m\n\u001b[0;32m     25\u001b[0m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    454\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    455\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    456\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:184\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:701\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(dtype):\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_period(freq\u001b[38;5;241m=\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfreq)\n\u001b[1;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtl\u001b[38;5;241m.\u001b[39mDatetimeLikeArrayMixin\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m, dtype, copy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:487\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    481\u001b[0m     is_datetime_or_timedelta_dtype(dtype)\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_equal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, dtype)\n\u001b[0;32m    483\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m is_float_dtype(dtype):\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;66;03m# disallow conversion between datetime/timedelta,\u001b[39;00m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;66;03m# and conversions for any datetimelike to float\u001b[39;00m\n\u001b[0;32m    486\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot cast DatetimeArray to dtype datetime64[M]"
     ]
    }
   ],
   "source": [
    "profiles = get_profiles(visits, orders, costs)\n",
    "profiles.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите минимальную и максимальную даты привлечения пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOLsbJpNWVwm"
   },
   "source": [
    "- Выясните, из каких стран пользователи приходят в приложение и на какую страну приходится больше всего платящих пользователей. Постройте таблицу, отражающую количество пользователей и долю платящих из каждой страны.\n",
    "- Узнайте, какими устройствами пользуются клиенты и какие устройства предпочитают платящие пользователи. Постройте таблицу, отражающую количество пользователей и долю платящих для каждого устройства.\n",
    "- Изучите рекламные источники привлечения и определите каналы, из которых пришло больше всего платящих пользователей. Постройте таблицу, отражающую количество пользователей и долю платящих для каждого канала привлечения.\n",
    "\n",
    "После каждого пункта сформулируйте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80LRB5-eWVwm"
   },
   "source": [
    "### Маркетинг\n",
    "\n",
    "- Посчитайте общую сумму расходов на маркетинг.\n",
    "- Выясните, как траты распределены по рекламным источникам, то есть сколько денег потратили на каждый источник.\n",
    "- Постройте график с визуализацией динамики изменения расходов во времени по неделям по каждому источнику. Затем на другом графике визуализируйте динамику изменения расходов во времени по месяцам по каждому источнику.\n",
    "- Узнайте, сколько в среднем стоило привлечение одного пользователя (CAC) из каждого источника. Используйте профили пользователей.\n",
    "\n",
    "Напишите промежуточные выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQE9emXqWVwm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poDjrQVHWVwn"
   },
   "source": [
    "### Оцените окупаемость рекламы\n",
    "\n",
    "Используя графики LTV, ROI и CAC, проанализируйте окупаемость рекламы. Считайте, что на календаре 1 ноября 2019 года, а в бизнес-плане заложено, что пользователи должны окупаться не позднее чем через две недели после привлечения. Необходимость включения в анализ органических пользователей определите самостоятельно.\n",
    "\n",
    "- Проанализируйте окупаемость рекламы c помощью графиков LTV и ROI, а также графики динамики LTV, CAC и ROI.\n",
    "- Проверьте конверсию пользователей и динамику её изменения. То же самое сделайте с удержанием пользователей. Постройте и изучите графики конверсии и удержания.\n",
    "- Проанализируйте окупаемость рекламы с разбивкой по устройствам. Постройте графики LTV и ROI, а также графики динамики LTV, CAC и ROI.\n",
    "- Проанализируйте окупаемость рекламы с разбивкой по странам. Постройте графики LTV и ROI, а также графики динамики LTV, CAC и ROI.\n",
    "- Проанализируйте окупаемость рекламы с разбивкой по рекламным каналам. Постройте графики LTV и ROI, а также графики динамики LTV, CAC и ROI.\n",
    "- Ответьте на такие вопросы:\n",
    "    - Окупается ли реклама, направленная на привлечение пользователей в целом?\n",
    "    - Какие устройства, страны и рекламные каналы могут оказывать негативное влияние на окупаемость рекламы?\n",
    "    - Чем могут быть вызваны проблемы окупаемости?\n",
    "\n",
    "Напишите вывод, опишите возможные причины обнаруженных проблем и промежуточные рекомендации для рекламного отдела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbNu9EXeWVwo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn9XBfZCWVwo"
   },
   "source": [
    "### Напишите выводы\n",
    "\n",
    "- Выделите причины неэффективности привлечения пользователей.\n",
    "- Сформулируйте рекомендации для отдела маркетинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8A6E79yWVwo"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
